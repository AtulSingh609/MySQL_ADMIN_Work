

==========================================================================================================

-- user creation
GRANT select ON *.* To 'abhishek'@'%' IDENTIFIED BY 'abhishek@123';

for specific table :

GRANT SELECT ON tmp.* TO 'aarti_master';

SHOW GRANTS for 'aaditya';

UPDATE `mysql`.`user` SET `References_priv`='Y' WHERE `Host`='%' and`User`='release';

update password

UPDATE mysql.user SET PASSWORD=PASSWORD('hop@123') WHERE USER='anshu@1';
FLUSH PRIVILEGES;

-- redshift 
GRANT SELECT ON ALL TABLES IN SCHEMA tmp TO query;


-- straight_join -- it will forcefully ask mysql to use left table scan first

SELECT table112.id,table112.bval1,table112.bval2,  
table111.id,table111.aval1  
FROM table112  
STRAIGHT_JOIN table111; 
or 
SELECT STRAIGHT_JOIN table112.id,table112.bval1,table112.bval2,  
table111.id,table111.aval1  
FROM table112  
_JOIN table111 on table112.id=table111.id; 
-- --------------------------------------------------------

-- queries in peak hours

select start_time,user_host,query_time,sql_text
from mysql.slow_log 
where start_time 
between '2017-01-06 08:00:00' and '2017-01-06 08:10:00';

-- queries in 2 hours

SELECT sum(query_time) summation, avg(query_time), count(query_time) cnt , user_host,  convert(sql_text using utf8) as sql
FROM `mysql`.`slow_log` l 
WHERE l.`start_time` > now() - interval 2 hour
group by substring(sql_convert(sql_text using utf8)text, 1, 35 )
order by cnt desc; 

select *,convert(sql_text using utf8) as `query` from  mysql.slow_log;


-- definer update

UPDATE `mysql`.`proc` p SET DEFINER = 'sp_user@%' WHERE specific_name='net_deposit' 

-- check content
select name,convert(body using utf8) from mysql.proc 
where db ='mysql'  and  convert(body using utf8) like '%change master%'
;



-- list of tables using column name
SELECT DISTINCT TABLE_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE COLUMN_NAME IN ('columnA','ColumnB') AND TABLE_SCHEMA='YourDatabase';
columns and table structures


SELECT  b.TABLE_NAME,b.column_name 
FROM INFORMATION_SCHEMA.COLUMNS  a right join INFORMATION_SCHEMA.COLUMNS b on a.table_name=b.table_name
WHERE  a.TABLE_SCHEMA='YourDatabase' and b.table_schema='YourDatabase2' and a.column_name is null union
SELECT  a.TABLE_NAME,a.column_name 
FROM INFORMATION_SCHEMA.COLUMNS  a left join INFORMATION_SCHEMA.COLUMNS b on a.table_name=b.table_name
WHERE  a.TABLE_SCHEMA='YourDatabase' and b.table_schema='YourDatabase2' and b.column_name is null;

create table tmp.tmp_singapore
SELECT  a.TABLE_NAME,a.column_name 
FROM INFORMATION_SCHEMA.COLUMNS  a where a.table_schema='Singapore';


create table tmp.tmp_seoul
SELECT  a.TABLE_NAME,a.column_name 
FROM INFORMATION_SCHEMA.COLUMNS  a where a.table_schema='Seoul';

select a.* from tmp_singapore a left join tmp_seoul b on a.table_name=b.table_name
where b.column_name is null;

select b.* from tmp_singapore a right join tmp_seoul b on a.table_name=b.table_name
where a.column_name is null;


-- for checking jobs
SELECT * FROM history.job_history ORDER BY job_id DESC LIMIT 5;
-- disable enable  events 
SELECT CONCAT("alter event ",event_schema,".",event_name , " DISABLE ON SLAVE;") FROM information_schema.events WHERE STATUS  = 'ENABLED';

-- size of table
SELECT table_name,table_schema , 
ROUND((SUM(data_length + index_length) / 1024 / 1024 / 1024), 2) AS  total_size
FROM information_schema.tables 
WHERE table_name ='inventory_history';



-- for checking job run successfully or not

select count(*) from history.job_history  
where end_date between now() and now()+ interval 330 minute;



------------------- temp queries  ---------------
SELECT * FROM information_schema.TRIGGERS WHERE ACTION_STATEMENT LIKE '%tmp%';
-- customers.before_customer_update

SELECT routine_name,routine_schema,routine_definition FROM information_schema.routines WHERE routine_definition LIKE '%tmp.%';

SELECT * FROM information_schema.events WHERE event_definition  LIKE '%tmp%';

Fragmantation ratio

select  ENGINE, TABLE_NAME,Round( DATA_LENGTH/1024/1024) as data_length , round(INDEX_LENGTH/1024/1024) as index_length, round(DATA_FREE/ 1024/1024) as data_free, (data_free/(index_length+data_length)) as frag_ratio from information_schema.tables  where  DATA_FREE > 0 order by frag_ratio desc;
-- -----------------------------------------------------------
-- -----------------------------------------------------------



which column is having which indexing
select * FROM information_schema.statistics 
WHERE table_schema ='whale_market_report'
AND table_name = 'user_ranks' AND column_name ='rank_name';



==========================================================================================================





WIFI Mobile : H0pM0b!l3
WIFI HOME: sidsibhihappy


MailID
puneet.kumar@hopscocth.in
naturelover@123

CRM: http://crm.hopscotch.in/intranet/welcome
UAT_CRM: https://uat.hopscotch.in/intranet/login#/customer
puneet.kumar@hopscotch.in
123456
info@nstechs.com / 123456

VPN
sudo openvpn ~/Desktop/Hopscotch.ovpn
puneet.kumar
naturelover@123

jenkins
http://jenkins.hs.internal:8080/
http://jenkins.uat.hopscotch.in/
http://jenkins.qa.hopscotch.in/

-- uat puneetkumar naturelover@123

JIRA
https://hopscotch.atlassian.net/projects/HW?selectedItem=com.atlassian.jira.jira-projects-plugin%3Arelease-page&status=unreleased
puneet.kumar
puneetkumar041@gmail.com

User id : devops@hopscotch.in
pwd      : zxcpoi@95

-- kibana
http://kibana.hs.internal:5601/app/kibana#/discover?_g=()

Redshift
===============================

jdbc:redshift://hs.calkks75sjbg.ap-south-1.redshift.amazonaws.com:5439/dev
User_Name: Query
Password: 5kl2GvIU


2. Jira :  Jira credential link send on  your mail. Please set credential.

3. CRM account:

Link : https://crm.hopscotch.in/intranet/

User name: puneet.kumar@hopscotch.in

Password: hopjust@789  .. Please change Password


hs-master-1.cjr7zdltfa3r.ap-southeast-1.rds.amazonaws.com
:3306

opesgenie
puneet.kumar@hopscotch.in
hop@123

-- ---------------------------------------------------------------
-- ---------------------------------------------------------------

-- To access redshift data Follow following steps.

SQL Workbench Download:
http://www.sql-workbench.net/downloads.html

Detailed steps for installation and connection:
http://docs.aws.amazon.com/redshift/latest/mgmt/connecting-using-workbench.html



-- To access Postgress user creation

GRANT USAGE ON SCHEMA android TO query;
GRANT SELECT ON ALL TABLES IN SCHEMA android TO query;


GRANT USAGE ON SCHEMA android,live_android TO query;
GRANT SELECT ON ALL TABLES IN SCHEMA android,live_android TO query;






in terminal
java -jar sqlworkbench.jar

-- ---------------------------------------------------------------	
-- ---------------------------------------------------------------
-- cloning of project
git clone https://github.com/hopscotchin/hs-service-project.git

`Dump of structures of full db ignoring 1 databases`

cd /home/puneetkumar/Desktop/softwares/hopscotch-env-project-master
cd home/puneetkumar/Desktop/softwares/hopscotch-env-project-master/prod-mumbai/keys
-- chmod 400 *


-- ---------------------------------------------------------------	
-- ---------------------------------------------------------------
-- -- -- -- -- Server login -- -- --
-- job server
ssh ubuntu@172.31.3.214 -i hs-prod-build.pem
cd db
-- build server
ssh ubuntu@172.31.3.27 -i build.pem
-- uat server
/home/puneet/hopscotch-env-project/uat/keys
#chmod 400 uat.pem
ssh ubuntu@35.154.146.190 -i uat.pem
-- qa server
/home/puneet/hopscotch-env-project/qa/keys
#chmod 400 uat.pem
ssh ubuntu@35.154.50.227 -i qa.pem
-- dev server
cd /home/puneet/hopscotch-env-project/dev/keys
#chmod 400 dev.pem
ssh ubuntu@35.154.162.61 -i dev.pem

ssh ../../
-- ---------------------------------------------------------------	
-- ---------------------------------------------------------------

/*   copying 
mysqldump -h bravodb.hs.internal -u HOPSCOTCH -p'5kl2GvIU5kl2GvIU' --databases analytics orders ordertracking personalization report supplychains tmp --no-data > bravo_db.sql

edit in bravod_db.sql


mysql -h uat.ccspmc3d8kkq.us-east-1.rds.amazonaws.com -u hsadmin -p'U(X9nD[x%L,'  < bravo_db_insertion.sql

mysql -h qa-cluster.cluster-ccspmc3d8kkq.us-east-1.rds.amazonaws.com -u hsadmin -p'U(X9nD[x%L,'  < bravo_db_insertion.sql

mysql -h dev.camv7qolninq.ap-south-1.rds.amazonaws.com -u hsadmin -p'U(X9nD[x%L,'  < bravo_db_insertion.sql

*/

cd db
pwd
/home/ubuntu/db

come to local (ctrl+D)
scp -i hs-prod-build.pem ubuntu@172.31.3.214:/home/ubuntu/db/bravo_db.sql /home/puneetkumar/Desktop/temp_files/

scp -i /Users/puneetkumar/Desktop/cm_app_config.sql /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem centos@'52.78.112.202'


open bravo_db.sql
and comment drop table command and replace create table with create table if not exists 


mysql All_US_DB_Cron_Tables

mysqldump -h uat.ccspmc3d8kkq.us-east-1.rds.amazonaws.com -u HOPSCOTCH -p'5kl2GvIU5kl2GvIU' --databases analytics orders ordertracking personalization report supplychains tmp --no-data > bravo_db.sql

#restore

mysql -h uat.ccspmc3d8kkq.us-east-1.rds.amazonaws.com -u hsadmin -p'U(X9nD[x%L,'  < bravo_db_insertion.sql

restore only one database
sed -n '/^-- Current Database: `dbname`/,/^-- Current Database: `/p' alldatabases.sql > output.sql
mysql -D mydatabase -o < dump.sql


-- build server
cd home/puneetkumar/Desktop/softwares/hopscotch-env-project-master/prod-mumbai/keys 	
172.31.3.27
ssh ubuntu@172.31.3.27 -i build.pem


-- copy content of one direvtory to other
cp -avr /home/vivek/letters /usb/backup



-- mysql -uroot -e "show slave status\G;"

mysql -h uat.ccspmc3d8kkq.us-east-1.rds.amazonaws.com -u hsadmin -p'U(X9nD[x%L,'-e "show slave status\G;"


============================================================================================================

-- FOR killing processes 

CALL mysql.rds_kill('822991');

set @@group_concat_max_len=1000000000000000000;
SELECT group_Concat(CONCAT("CALL mysql.rds_kill(",id,")") separator ";") FROM information_schema.processlist WHERE 
user='tds_dbuser' and db='tdsskydb';

SELECT CONCAT("CALL mysql.rds_kill(",id,");") FROM information_schema.processlist WHERE db='proxy' AND COMMAND='Sleep'

SELECT USER,SUBSTRING_INDEX(HOST,':',1) AS ho,COUNT(1) AS cnt FROM information_Schema.processlist WHERE info IS  NULL GROUP BY `user`,ho ORDER BY cnt DESC;

-- for error skip
CALL history.error_skip();
CALL mysql.rds_stop_replication;
CALL mysql.rds_start_replication;


show master status;
file -- 
mysql-bin-changelog.001386

CALL mysql.rds_next_master_log(001386);

-- to check locks on table
show engine innodb status
SELECT *
FROM information_schema.innodb_lock_waits w
INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;

SELECT CONCAT("CALL mysql.rds_kill(",b.trx_mysql_thread_id,");") 
FROM information_schema.innodb_lock_waits w
INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id
where b.trx_query like 'update customers.customerdetail%last_login_ip%';

SELECT CONCAT("CALL mysql.rds_kill(",b.trx_mysql_thread_id,");") 
FROM information_schema.innodb_lock_waits w
INNER JOIN information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_id
INNER JOIN information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id
where b.trx_state!=  'LOCK WAIT';


PROMPT> CALL mysql.rds_rotate_slow_log;
PROMPT> CALL mysql.rds_rotate_general_log; 

MySQL Command Corrosponding Stored Proc
CHANGE MASTER TO  mysql.rds_set_external_master
START SLAVE     mysql.rds_start_replication
STOP SLAVE      mysql.rds_stop_replication



mysql> call mysql.rds_stop_replication;
mysql> call mysql.rds_reset_external_master;
MySQL> call mysql.rds_start_replication;
mysql> CALL mysql.rds_set_external_master ('servername', port, 'user', 'password', 'binlog-file', binlog-offset, 0);
e.g.
call mysql.rds_set_external_master ('master.camv7qolninq.ap-south-1.rds.amazonaws.com', 3306, 'HOPSCOTCH', 'h0psc**tch7823yioi', 'mysql-bin-changelog.017234', 41803638, 0);
Few links for references:

http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/mysql_rds_set_external_master.html

https://www.elitmus.com/blog/technology/setting-up-amazon-rds-as-a-slave-to-a-self-managed-mysql-server/



online alter

alter table <table_name> add key(id) algorithm=inplace lock=none;


-- image download process
1)copy attachment  & add make it csv
2)replace "?dl=0" with blank
3)and login to rima server and make directory of that day
4)ssh rima@192.168.1.5
5)password
6)cd /home/rima/catalogImages
7)mkdir 09022017/ 
8)cp -R  08022017/* 09022017/                                                                            */
-- temp directory is not there cp -R 09022017/ temp

9)cd 09022017/
10)-rvf *.jpg
11) ls -al
12) vim tmp.csv
-- (delete all by d and GG) and paste the content of downloaded csv file
./imagesURL.sh



mysqlbinlog
--read-from-remote-server     
--host=slave.camv7qolninq.ap-south-1.rds.amazonaws.com     
--port=3306
--user hsadmin
--password 'asdf234@#TYwew#@rre'
--result-file=/home/puneetkumar/Downloads/output.txt     
mysql-bin-changelog.004768


############


mysqldump -u [username] -p -t -T/path/to/directory [database] --FIELDS TERMINATED BY ',' --OPTIONALLY ENCLOSED BY '"' -- LINES TERMINATED BY '\n',




-- infile -- outfile

SELECT customer_id, firstname, surname INTO OUTFILE '/exportdata/customers.txt'
FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n';
FROM customers;


LOAD DATA LOCAL INFILE '/exportdata/customers.txt' INTO TABLE abc
FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES
(col1, col2, col3, col4, col5...);


-- if getting error of charset

LOAD DATA LOCAL INFILE 'C:/Users/me/Desktop/questions.csv' INTO TABLE homestead_daily.questions
CHARACTER SET latin1
FIELDS TERMINATED BY ',' 
OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES;


drop table tmp.tmp_cost_update;
create table tmp.tmp_cost_update(key(product_id),key(sku))
select product_id,sku,msrp,cost_price from products.productitem limit 0;
LOAD DATA LOCAL INFILE '/Users/puneet/Desktop/msrp_cp.csv' INTO TABLE tmp.tmp_cost_update
FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES;


-- first_date
-- last_date
#set @first_date=DATE_FORMAT(DATE_sub(CURDATE(), INTERVAL 1 MONTH), '%Y-%m-01');
SET @last_date=LAST_DAY(CURDATE() - INTERVAL 1 MONTH);


-- ******************************************************

-- for special characters
WHERE (CONVERT(`companyName` USING ASCII) <> companyName
OR CONVERT(companyName USING ASCII) RLIKE '[[.NUL.]-[.US.][.DEL.]]')

MATCH AGAINST
SELECT * FROM `US_company_master`.tbl_company_master WHERE MATCH(catidlineage)
AGAINST('/1020996325/');

for counting autosuggest
SELECT CONCAT("
select count(*),'",REPLACE(REPLACE(table_name,'tbl_autosuggest_company_',''), '_NEW2','') ,"'
from db_autosuggest.",table_name," union") FROM information_schema.tables
WHERE table_name LIKE 'tbl_autosuggest_company_%_NEW2' AND
table_schema='db_autosuggest' ;

for counting splits
SELECT CONCAT("
select count(*),",REPLACE(table_name,'tbl_catSplit_',''),"
from US_category_split.",table_name," union") FROM information_schema.tables
WHERE table_name LIKE 'tbl_catSplit_%' AND table_schema='US_category_split' AND
LENGTH(table_name)<=15 ;
#For verifying weather integer prsnt in column or not #

10.0.1.21
SELECT state,ct_name FROM `db_area`.`tbl_city_master_new_rev`WHERE ct_name REGEXP '^-?[0-9]+$';

For finding out of keyboard characters
SELECT parentid,state,city FROM db_company.tbl_company_master WHERE city REGEXP '[^ -~]'
OR state REGEXP '[^ -~]';

query to find special characters
WHERE (CONVERT(`companyName` USING ASCII) <> companyName
OR CONVERT(companyName USING ASCII) RLIKE '[[.NUL.]-[.US.][.DEL.]]')
for finding small p in parentid of table
SELECT parentid FROM db_company.`tbl_companymaster_generalinfo` WHERE parentid REGEXP
BINARY '^p' ;

integer in integer
REGEXP '^[0-3]'to find duplicate values
SELECT id,sal FROM puneet
WHERE id IN (SELECT id FROM puneet
GROUP BY id
HAVING COUNT(id)>1)
ORDER BY id;

for finding duplicate picture of same docid
SELECT COUNT(DISTINCT product_url) FROM tbl_catalogue_details GROUP BY docid;


DROP PROCEDURE IF EXISTS state_update //
CREATE PROCEDURE state_update()
BEGIN
DECLARE done INT DEFAULT 1;
DECLARE i,p INT;
DECLARE var_state_abbr,var_statename VARCHAR(50);
DECLARE crsr1 CURSOR FOR SELECT statename,stateabbr FROM
`db_area`.`state_abbrevations`;
DECLARE CONTINUE HANDLER FOR NOT FOUND SET done =0;
OPEN crsr1;
WHILE done=1 DO
FETCH crsr1 INTO var_statename,var_state_abbr;
UPDATE `db_company`.temp_grouped_state_city SET
multiple_states=REPLACE(multiple_states,CONCAT(',',var_state_abbr,','),CONCAT(',',var_statename,
','));
END WHILE;
UPDATE `db_company`.temp_grouped_state_city SET multiple_states = TRIM(BOTH ',' FROM
multiple_states);CLOSE crsr1;
END //
DELIMITER ;


-- killing heavy queries or connections


CREATE TABLE tempo.tbl_killed_connection_log(KEY(query_user),KEY(query_host),KEY(query_time),KEY(query_info(750)))
SELECT  id, USER AS query_user,HOST AS query_host,TIME AS query_time,info AS query_info  FROM information_schema.PROCESSLIST LIMIT 0;

DELIMITER $$
DROP PROCEDURE IF EXISTS history.purge_idle$$
CREATE PROCEDURE history.purge_idle()
BEGIN 
DECLARE c_id BIGINT(21);
DECLARE done_handler INT(5) DEFAULT '0';
DECLARE done INT DEFAULT 0;
DECLARE c CURSOR FOR SELECT id FROM information_schema.processlist
WHERE info IS NOT NULL AND db IS NOT NULL AND TIME >1800 
ORDER BY TIME  DESC;
DECLARE CONTINUE HANDLER FOR NOT FOUND SET done=TRUE;
SET done = 0;


CREATE TABLE IF NOT EXISTS history.`purge_connection_log` (
`id` BIGINT(21) UNSIGNED NOT NULL DEFAULT '0',
`query_user` VARCHAR(16) CHARACTER SET utf8 NOT NULL DEFAULT '',
`query_host` VARCHAR(64) CHARACTER SET utf8 NOT NULL DEFAULT '',
`query_time` INT(7) NOT NULL DEFAULT '0',
`query_info` LONGTEXT CHARACTER SET utf8,
`insert_time` DATETIME NOT NULL DEFAULT '0000-00-00 00:00:00' ,
KEY `query_user` (`query_user`),
KEY `query_host` (`query_host`),
KEY `query_time` (`query_time`),
KEY `query_info` (`query_info`(255)),
KEY `insert_time` (`insert_time`)
) ENGINE=INNODB DEFAULT CHARSET=latin1;


INSERT INTO history.purge_connection_log(id,query_user,query_host,query_time,query_info,insert_time)
SELECT  id, USER AS query_user,HOST AS query_host,TIME AS query_time,info AS query_info,NOW() AS insert_time  FROM information_schema.PROCESSLIST
WHERE info IS NOT NULL AND TIME >1800 ;
--       
OPEN c;
REPEAT
FETCH  c  INTO c_id ;
IF NOT done THEN 

CALL mysql.rds_kill(c_id);

SET done = done_handler;
END IF;      
UNTIL done END REPEAT;
CLOSE c;
END $$
DELIMITER ;

############

#DROP EVENT  tempo.schedule_test;

DELIMITER $$

ALTER EVENT  history.purge_idle_connection
ON SCHEDULE EVERY 10 MINUTE STARTS '2017-01-18 10:11:28' ON COMPLETION
PRESERVE  DO 
BEGIN
CALL history.purge_idle();
END$$

DELIMITER ; 

ALTER event history.purge_idle_connection ENABLE;



SHOW STATUS LIKE '%event%';

If null Conditions:
SELECT IFNULL(IFNULL(IFNULL(tele_4,tele_3),tele_2),tele_1) AS phone FROM
`US_company_master`.`tbl_company_master`;
SELECT IF(IF(IF(tele_4 IS NULL,tele_3,tele_4) IS NULL,tele_2,tele_3) IS NULL,tele_1,tele_2) AS
phone FROM `US_company_master`.`tbl_company_master`;

MATCH AGAINST
SELECT * FROM `US_company_master`.tbl_company_master WHERE MATCH(catidlineage)
AGAINST(99164618)

Count each states count
SELECT SUM(IF(IFNULL(`Business Name`,'')<>'',1,0)) AS `Business Name`,
SUM(IF(IFNULL(`id`,0)<>0,1,0)) AS `id`, FROM tbl_Canada_initial_may2014;
for all columns we use exel formula concatenation to concate columns
result will cm in :
A
B
C
-- 200 100 300
select these two colmns and in paste option paste special transpose then we will get the result
#LSSI_Freq updated with sum of reviews always


===============================================================================================

#Recreate UAT
Solution :
1. git checkout release
2. git pull -p
3. git branch -D uat  (to remove existing uat branch)
4. git checkout -b uat origin/uat  (recreate local uat branch from remote uat)


-- cloning Hopscotch projectinot local
git clone https://github.com/hopscotchin/hopscotch.git

user: puneetkumar041@gmail.com
password: naturelover@123
HOPSCOTCH project: https://github.com/hopscotchin/hopscotch

git branch

-- create braches 
1. git checkout -b qa origin/qa (git branch qa + git checkout qa)
2. git status
3. git pull


1. git checkout -b uat origin/uat (git branch uat + git checkout uat)
2. git status
3. git pull

1. git checkout -b release origin/release (git branch release + git checkout release)
2. git status
3. git pull


=====================================================================================
-- 


SET @sqlv= CONCAT('SELECT * FROM ', @table);
PREPARE stmt FROM @sqlv;
EXECUTE stmt;
DEALLOCATE PREPARE stmt;

DELIMITER $$

USE `db`$$

DROP PROCEDURE IF EXISTS `gujarat_monthwise_data`$$

CREATE PROCEDURE `gujarat_monthwise_data`(IN start_date DATE, IN end_date DATE)
BEGIN 
DECLARE done_handler 		INT(5) DEFAULT '0';
DECLARE v_district_name 	VARCHAR(200);
DECLARE v_month_name 		VARCHAR(200);
DECLARE v_file_name 		VARCHAR(200);
DECLARE v_start_date 		DATE;
DECLARE v_end_date 		DATE;
DECLARE done 			INT DEFAULT 0;

DECLARE curr_update CURSOR FOR SELECT DISTINCT district FROM STATION_V1 WHERE district IS NOT NULL;
DECLARE CONTINUE HANDLER FOR NOT FOUND SET done=TRUE;
SET done = 0;
SET v_start_date=start_date;
SET v_end_date  =end_date;


OPEN curr_update;
REPEAT
FETCH  curr_update  INTO v_district_name ;
IF NOT done THEN 

-- SQL QUERIES one by one  using that variable 
-- SET @district_name= ( SELECT DISTINCT district FROM STATION_V1); 
SET v_month_name=MONTHNAME(v_start_date);
SET v_file_name=CONCAT(v_district_name,v_month_name);
-- WHILE (@district_name IS NOT NULL)
-- DO 
SELECT st.STATE,st.DISTRICT,st.TEHSIL,st.STATION_NAME,sd.IS_INTERPOLATED,sd.IS_UPLOADED,sd.IS_UPDATED,sd.ID,DATE(sd.DATA_DATE) AS datadate,DATE_FORMAT(sd.DATA_DATE,'%H:%i') AS TIME, ROUND(Temp_Avg,1) AS AvgTemp,ROUND(sd.Temp_Max,1) AS MaxTemp,ROUND(sd.Temp_Min,1) AS MinTemp,ROUND(sd.Hmdt_Avg) AS AvgRh,ROUND(sd.DewPoint,1) AS DewPoint, ROUND(sd.Wind_Avg,1) AS Wind_Avg,sd.Wind_Dir AS WindDirection,ROUND(sd.Wind_Max,1) AS Wind_Max,ROUND(sd.Wind_Min,1) AS Wind_Min,sd.Rain_Avg AS AvgRain, sd.Rain_Max AS MaxRain,sd.Rain_Min AS MinRain,ROUND(sd.Battery,1) AS Battery,ROUND(sd.PV,1) AS PV,  DATE_FORMAT(sd.DATA_DATE,'%Y-%m-%d') AS datadateformat INTO OUTFILE 'home/saurabh/Documents/gujarat_districtwise_data/' FROM STATION_DATA_V1_TILL_2017_DNT_DEL sd,STATION_V1 st WHERE st.ID=sd.IMEI_ID  AND sd.data_date>=v_start_date AND sd.data_date< v_end_date AND sd.IS_UPDATED='1'  AND sd.IMEI_ID IN (SELECT  ID FROM STATION_V1 WHERE STATE='Gujarat' AND ACTIVE=1) AND st.district=v_district_name ORDER BY sd.data_date ASC;



SET @sqlv= CONCAT("SELECT st.STATE,st.DISTRICT,st.TEHSIL,st.STATION_NAME,sd.IS_INTERPOLATED,sd.IS_UPLOADED,sd.IS_UPDATED,sd.ID,DATE(sd.DATA_DATE) AS datadate,DATE_FORMAT(sd.DATA_DATE,'%H:%i') AS TIME, ROUND(Temp_Avg,1) AS AvgTemp,ROUND(sd.Temp_Max,1) AS MaxTemp,ROUND(sd.Temp_Min,1) AS MinTemp,ROUND(sd.Hmdt_Avg) AS AvgRh,ROUND(sd.DewPoint,1) AS DewPoint, ROUND(sd.Wind_Avg,1) AS Wind_Avg,sd.Wind_Dir AS WindDirection,ROUND(sd.Wind_Max,1) AS Wind_Max,ROUND(sd.Wind_Min,1) AS Wind_Min,sd.Rain_Avg AS AvgRain, sd.Rain_Max AS MaxRain,sd.Rain_Min AS MinRain,ROUND(sd.Battery,1) AS Battery,ROUND(sd.PV,1) AS PV,  DATE_FORMAT(sd.DATA_DATE,'%Y-%m-%d') AS datadateformat INTO OUTFILE 'home/saurabh/Documents/gujarat_districtwise_data/", v_district_name,"' FROM STATION_DATA_V1_TILL_2017_DNT_DEL sd,STATION_V1 st WHERE st.ID=sd.IMEI_ID  AND sd.data_date>='",v_start_date,"' AND sd.data_date< '",v_end_date,"' AND sd.IS_UPDATED='1'  AND sd.IMEI_ID IN (SELECT  ID FROM STATION_V1 WHERE STATE='Gujarat' AND ACTIVE=1) AND st.district=v_district_name ORDER BY sd.data_date ASC;");
PREPARE stmt FROM @sqlv;
EXECUTE stmt;
DEALLOCATE PREPARE stmt


SET done = done_handler;
END IF;      

UNTIL done END REPEAT;
CLOSE curr_update;
ELSE

END$$

DELIMITER ;


uname -id 32 bit or 64 bit

Grants for selected db:

select distinct concat("GRANT SELECT ON ",table_schema,".* TO 'amjad_it'@'%' IDENTIFIED BY  'UGc6DkKgU7';") from information_schema.tables
where table_schema not  in ( 'tmp','innodb','db_config','information_schema','performance_schema','sys','mysql');

CREATE USER 'francis'@'localhost' IDENTIFIED BY 'frank'
->     WITH MAX_QUERIES_PER_HOUR 20
->          MAX_UPDATES_PER_HOUR 10
->          MAX_CONNECTIONS_PER_HOUR 5
->          MAX_USER_CONNECTIONS 2;

ALTER USER 'user1'@'localhost' WITH MAX_USER_CONNECTIONS 0;

for monitoring

watch -n1 'du -sh *'


directly writing to csv

mysql -udb_user -p -h broc-rds-1-cluster.cluster-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com richesfx_report -e 
"select * from mt4_trades where close_time !='1970-01-01 00:00:00' and  close_time < '2017-08-07 59:59:59' limit 2000000,1000000" > 
richesfx_report_close_trades_2017_08_07_2000000_3000000.csv


character set : UTF8
ALTER TABLE ranks MODIFY rank_zh varchar(45) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '';
ALTER TABLE offline_accessinfo  change `comment` `comment`  varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '';



#outuput to csv and share
ssh -i /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem  centos@52.78.112.202



SELECT COUNT(1) from mt4_trades_archive JOIN mt4_users ON mt4_users.LOGIN = mt4_trades_archive.LOGIN
WHERE cmd IN (0,1)  and CLOSE_TIME > '2017-09-01 00:00:00' and  CLOSE_TIME < '2017-09-16 00:00:00' ;

mysql -udb_user -p -P 3356 -h shard-1-report-bb.private-sing.com -D jetfx_report  -e "SELECT TICKET, 
mt4_trades_archive.LOGIN, mt4_users.GROUP, SYMBOL,
(CASE WHEN CMD = 0 THEN 'BUY' WHEN CMD = 1 THEN 'SELL' 
WHEN CMD = 2 THEN 'BUY LIMIT' WHEN CMD = 3 THEN 'SELL LIMIT' WHEN CMD = 4 THEN 'BUY STOP' WHEN CMD = 5 THEN 'SELL STOP' 
WHEN CMD = 6 THEN 'BALANCE' WHEN CMD = 7 THEN 'CREDIT' ELSE NULL END) as CMD, VOLUME/100 AS VOLUME, 
OPEN_TIME AS 'OPEN TIME', OPEN_PRICE AS 'OPEN PRICE',SL, TP,CLOSE_TIME AS 'CLOSE TIME', SWAPS,CLOSE_PRICE AS 'CLOSE PRICE',
PROFIT, mt4_trades_archive.COMMENT from mt4_trades_archive JOIN mt4_users ON mt4_users.LOGIN = mt4_trades_archive.LOGIN 
WHERE cmd IN (0,1) and CLOSE_TIME > '2017-09-01 00:00:00' and  CLOSE_TIME < '2017-09-16 00:00:00' ;" >jet_1_16_sept.csv 

exit

copy on local

scp -i /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem -r  centos@52.78.112.202:/tmp/jetfx_backup_csv/*.csv /Users/puneetkumar/Documents/jetfx_data/


puneet.kumar/Desktop/test/keys
*/
SELECT CONCAT("
select id,database, replace('",table_Schema,"','deerv2_','') from ",table_Schema,".white_labels union") FROM information_schema.tables
WHERE table_name = 'white_label_settings' ;

data copy /  clone of DB

select concat("create table my_vgfx_qa_bb_db.",table_name," like ",table_Schema,".",table_name," ;") from information_schema.tables where table_schema like 'my_vgfx_qa_db';


select concat("insert into my_vgfx_qa_bb_db.",table_name," select * from ",table_Schema,".",table_name," ;") from information_schema.tables where table_schema like 'my_vgfx_qa_db';

mysql -udb_user -p  -h blackbuck-fvm-cluster.cluster-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com -D tmp  -e "select  distinct a.*,ifnull(b.bo_sum,0) as bo_sum from tmp.tmp_d_login_direct_sponser2 a left join tmp.tmp_login_direct_sponser_final b on a.downline=b.downline and b.rank='d' ;" 
>/Users/puneet.kumar/Desktop/tmp_d_login_direct_sponser_BO_vol.csv 

mysqldump -h <host> -u <user> -p'password'  db |  mysql -h <host> -u <user> -p'password'  db 



mysqldump -h priv-deer-fvm-report.cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com -u  db_user -P3356 -p  tmp tmp_overall2 | mysql -h priv-fvm-crm.fintech -u db_user -P3356 -p tmp

mysqldump --single-transaction --max-allowed-packet=1G   -h priv-qa.fintech -u db_user -p'DBA%$#321'  bb_v2_qa  >/tmp/bb_v2_qa_20july.sql 

mysql -h demo.cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com -u db_user -p'DBA%$#321' --max-allowed-packet=1G vtfx_report </tmp/vtfx_report.sql 

--ignore-table={db_test.table1,db_test.table3,db_test.table4}


#########################################
WM
# terminated backup jetfx

ssh -i /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem  centos@52.78.112.202

/tmp/terminated_backup/

mysqldump -h shard-1-bb.private-sing.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356 --triggers --routines jetfx_bb_ad > jetfx_bb_ad_terminated_backup_15072017.sql


mysqldump -h shard-1-deer.private-sing.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356  jetfx_wm > jetfx_wm_terminated_backup_15072017.sql


mysqldump -h shard-1-report-deer.private-sing.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356  jetfx_report > jetfx_wm_report_terminated_backup_15072017.sql

CRM App DB

# Query before terminating WL and make report

rank,group 

select ua.login,ud.realname as `name`,r.rank,og.`name` as `group` ,ua.agent_account,
cs.name as commsion_scheme,ud.country,ud.email,ud.phone, urp.probation_start_date,
urp.probation as probabtion_status,urp.probation_rank,urp.id as probation_rank_id,urp.created_at,urp.updated_at
from user_data  ud 
join user_accounts ua  on ud.id=ua.user_ref_id 
join ranks r on ua.user_rank=r.id
join offline_mt4_group og   on ua.account_type=og.id
join   commission_schema cs on ua.commission_id=cs.id
join user_rank_probation urp on ua.login=urp.login;

goldant_share_report_220917.csv


#########################################

Users/puneet.kumar
# terminated backup goldant

ssh -i /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem  centos@52.78.112.202

/home/terminated_backup/CRM/

mysqldump -h shard-1-bb.private-sing.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356 --triggers --routines jetfx_bb_ad > jetfx_bb_ad_terminated_backup_15072017.sql



mysqldump -h shard-1-deer.private-sing.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356  jetfx_wm > jetfx_wm_terminated_backup_15072017.sql



## CRM / WM shut down  process

#Private infra 
mysqldump -h priv-bb-shard-1.cluster-ro-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com --max-allowed-packet=1G -u db_user -p'DBA%$#321' -P 3356 --events --triggers --routines benefx_bb_ad > benefx_bb_ad_22072018.sql


mysql -udb_user -p -h priv-bb-shard-1.cluster-ro-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com benefx_bb_ad -u db_user -p'DBA%$#321' -P 3356 -e "select ua.login,ud.realname as name,r.rank,og.name as group_name,ua.agent_account, cs.name as commsion_scheme,ud.country,ud.email,ud.phone, urp.probation_start_date, urp.probation as probabtion_status,urp.probation_rank,urp.id as probation_rank_id,urp.created_at,urp.updated_at from user_data  ud join user_accounts ua  on ud.id=ua.user_ref_id join ranks r on ua.user_rank=r.id join offline_mt4_group og  on ua.account_type=og.id join commission_schema cs on ua.commission_id=cs.id join user_rank_probation urp on ua.login=urp.login;" > benefx_report.csv


-- WM
mysqldump --single-transaction --max-allowed-packet=1G   -h itsupport-report-slave-shard2.cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com -u db_user -p -P 3356  benefx_report --ignore-table=benefx_report.mt4_users --ignore-table=benefx_report.mt4_trades --ignore-table=benefx_report.mt4_config --ignore-table=benefx_report.mt4_prices --ignore-table=benefx_report.MT4_PRICES --ignore-table=benefx_report.MT4_CONFIG --ignore-table=benefx_report.MT4_TRADES --ignore-table=benefx_report.MT4_USERS | gzip -c  > /home/migrated_database_backup/benefx_report-WM-Report.sql.gz

########################

CRM Report server Public

drop database broccap_report;

create database  MT4_Plugin_oZ1;        
GRANT  SELECT on MT4_Plugin_oZ1.*  TO 'brocc_1'@'%' IDENTIFIED BY  'HcL5ukZjN3';  -- user  for selection

GRANT  SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES , EXECUTE on MT4_Plugin_oZ1.*  TO 'brocc'@'%' IDENTIFIED BY  'Bup9LxcgS1';  -- rajeev ranjan for synching 

flush privileges;

use MT4_Plugin_oZ1;
CREATE TABLE `mt4_trades_archive` (
`TICKET` int(11) NOT NULL,
`LOGIN` int(11) NOT NULL,
`SYMBOL` char(16) NOT NULL,
`DIGITS` int(11) NOT NULL,
`CMD` int(11) NOT NULL,
`VOLUME` int(11) NOT NULL,
`OPEN_TIME` datetime NOT NULL,
`OPEN_PRICE` double NOT NULL,
`SL` double NOT NULL,
`TP` double NOT NULL,
`CLOSE_TIME` datetime NOT NULL,
`EXPIRATION` datetime NOT NULL,
`REASON` int(11) NOT NULL DEFAULT '0',
`CONV_RATE1` double NOT NULL,
`CONV_RATE2` double NOT NULL,
`COMMISSION` double NOT NULL,
`COMMISSION_AGENT` double NOT NULL,
`SWAPS` double NOT NULL,
`CLOSE_PRICE` double NOT NULL,
`PROFIT` double NOT NULL,
`TAXES` double NOT NULL,
`COMMENT` char(32) NOT NULL,
`INTERNAL_ID` int(11) NOT NULL,
`MARGIN_RATE` double NOT NULL,
`TIMESTAMP` int(11) NOT NULL,
`ARCHIVE_TICKET` int(11) NOT NULL DEFAULT '0',
PRIMARY KEY (`TICKET`),
KEY `INDEX_LOGIN` (`LOGIN`),
KEY `INDEX_CLOSETIME` (`CLOSE_TIME`),
KEY `IDX_COMMENT` (`COMMENT`),
KEY `CMD` (`CMD`),
KEY `PROFIT` (`PROFIT`),
KEY `VOLUME` (`VOLUME`),
KEY `SYMBOL` (`SYMBOL`),
KEY `comp` (`CMD`,`LOGIN`,`CLOSE_TIME`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;



-- Marquis_report_slave2

overall summary datewise

select * from  valourfx_report.tbl_overall_summary_datewise where close_time='2017-09-26';
delete  from valourfx_report.tbl_overall_summary_datewise where close_time='2017-09-26';

call valourfx_report.sp_overall_summary_data_prepare();
call valourfx_report.sp_overall_summary_data_prepare_daywise();



-- 

excel concatenate query
=CONCATENATE("update user_data set name='",C1,"' where login=",A1,";")


query to check privilges of users

select * from( select distinct User,group_concat(distinct Db) as db,
replace(replace(trim(both ',' from concat_ws(',',
if(Select_priv="Y","Select",""), 
if(Insert_priv="Y","Insert",""), 
if(Update_priv="Y","Update",""), 
if(Delete_priv="Y","Delete",""), 
if(Create_priv="Y","Create",""), 
if(Drop_priv="Y","Drop",""), 
if(Grant_priv="Y","Grant",""), 
if(References_priv="Y","References",""), 
if(Index_priv="Y","Index",""), 
if(Alter_priv="Y","Alter",""), 
if(Create_tmp_table_priv="Y","Create_tmp_table",""), 
if(Lock_tables_priv="Y","Lock_tables",""), 
if(Create_view_priv="Y","Create_view",""), 
if(Show_view_priv="Y","Show_view",""), 
if(Create_routine_priv="Y","Create_routine",""), 
if(Alter_routine_priv="Y","Alter_routine",""), 
if(Execute_priv="Y","Execute",""), 
if(Event_priv="Y","Event",""), 
if(Trigger_priv="Y","Trigger,",""))),',,,,',','),',,,,',',') as priv
from mysql.db group by user,priv) a 
where user not in ('db_user') and user not like '%zyme%' and priv!='select';



#########################################

###  process for killing read only user from productions


DELIMITER $$
DROP PROCEDURE IF EXISTS tmp.purge_idle$$
CREATE PROCEDURE tmp.purge_idle()
BEGIN 
DECLARE c_id BIGINT(21);
DECLARE done_handler INT(5) DEFAULT '0';
DECLARE done INT DEFAULT 0;
DECLARE c CURSOR FOR SELECT id FROM information_schema.processlist WHERE user in 
('abhishek_bb','afroj_bb','alisha_tester','aman_bb','amjad_it','ashish_bb','atul_it','ayush_bb','bharat_bb','bharat_temp','bismai_bb',
'dhruv_it','gaurav_it','ikhlak_it','itsupport','kuldeep_it','madhu_it','nargis_bb','navi_tester','newton_bb','nishant_bb','priya_it',
'puneet_bb','qa','ravi_it','saba_it','sashi_bb','satessh_bb','shashank_bb','sheela_it','shubham_it','sonam_tester','susmita_bb',
'syed_it','vivek_bb');

DECLARE CONTINUE HANDLER FOR NOT FOUND SET done=TRUE;
SET done = 0;

--           
OPEN c;
REPEAT
FETCH  c  INTO c_id ;
IF NOT done THEN 
CALL mysql.rds_kill(c_id);
SET done = done_handler;
END IF;      
UNTIL done END REPEAT;
CLOSE c;
END $$
DELIMITER ;

CALL tmp.purge_idle();


sp_user

#hy,my,rcm,fvm,sky9,tds,oufx,sing,seoul

GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, CREATE ROUTINE, 
ALTER ROUTINE, EVENT, TRIGGER ON *.* TO 'sp_user'@'%' IDENTIFIED BY PASSWORD '*638195ED32E72EF10C62C3289C6ABE942EC24A49';







Query for checking reference of a table: (foreign key constraint)

SELECT
TABLE_NAME,
COLUMN_NAME,
  , 
REFERENCED_TABLE_NAME,
REFERENCED_COLUMN_NAME
FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE
WHERE
REFERENCED_TABLE_NAME = 'My_Table';



mysql -udb_user -p -h broc-rds-cluster-hy-cluster.cluster-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com hystarfish_report -e "SELECT login,name,address,email,`group`,regdate,prevbalance AS last_balance FROM mt4_users WHERE mt4_users.group NOT LIKE '%test%' AND mt4_users.NAME NOT LIKE '%test%' AND mt4_users.COUNTRY NOT LIKE '%test%' AND mt4_users.CITY NOT LIKE '%test%'AND mt4_users.STATE NOT LIKE '%test%' AND mt4_users.ZIPCODE NOT LIKE '%test%' AND mt4_users.ADDRESS NOT LIKE '%test%' AND mt4_users.PHONE NOT LIKE '%test%' AND mt4_users.EMAIL NOT LIKE '%test%' AND mt4_users.`COMMENT` NOT LIKE '%test%' AND mt4_users.ID NOT LIKE '%test%' AND mt4_users.STATUS NOT LIKE '%test%' AND mt4_users.CURRENCY NOT LIKE '%test%' AND mt4_users.PASSWORD_PHONE NOT LIKE '%test%' AND `mt4_users`.`GROUP` NOT IN ('SFVPROD' , 'MTEMP','MTEMP2','HYVPROD','HYMTEMP', 'MQSDEL', 'RCVDEL', 'FFVDEL', 'VGVDEL') AND enable = 1 limit 7000000;" > hy_users.csv













/*
Host : priv-rcm-crm-report.fintech.
User : rcm_admin
Pass : tJhD7dCxgr
db_name : rcm_report
port : 3356
*/

copying tables and routines

mysqldump -h priv-rcm-crm-report.fintech -u db_user -p'DBA%$#321'  tmp group_update |  mysql -h priv-rcm-crm.fintech -u db_user -p'DBA%$#321' tmp 

only routines


mysqldump -h blackbuck-fvm-cluster.cluster-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com  fortfx_bb_ad -udb_user -p'DBA%$#321' --routines --no-create-info --no-data --no-create-db --skip-opt >  fortfx_bb_ad_routines.sql

mysqldump -h broc-rds-cluster-vgfx-fort-mq-cluster.cluster-cz1rcbccvawq.ap-northeast-2.rds.amazonaws.com fortfx_report -u db_user -p'DBA%$#321' --routines --no-create-info --no-data --no-create-db --skip-opt >  fortfx_report_routines.sql




scp -i /Users/puneet.kumar/Desktop/test/keys/privinfra-db-backup.pem centos@52.78.112.202:/tmp/tinyee_bb_ad_dump.sql /Users/puneet.kumar/Desktop/

#-- skip errors

#!/bin/bash 
slave=`mysql -uroot -e "show slave status\G;" |grep "Last_SQL_Errno" |cut -d : -f 2` 
Error=`mysql -uroot -e "show slave status\G;" |grep "Last_Error"` 
if [ $slave = 1032 ] 
    then 
    echo "======$(date)======" >> /var/log/slave_skip.log 
    echo $Error >> /var/log/slave_skip.log 
    mysql -uroot -e "stop slave; set global sql_slave_skip_counter = 1; start slave;" 
else 
#    echo " Slave running without error" 
    echo " $(date)=====Slave running without error=====" 
fi

###############################################################################

#-- replication status
#!/bin/bash

# Configuration - where to find the mysql command line client binary
# and the file with the configuration the client should use to connect.
# The DELAY_THRESHOLD is when to alert for seconds_behind_master being too high.
MYSQL=/usr/bin/mysql
MYSQL_CNF=/etc/my.cnf
DELAY_THRESHOLD=60

# Get the output of the SHOW SLAVE STATUS command
SLAVE_STATUS=$(${MYSQL} --defaults-file=${MYSQL_CNF} --vertical --execute="SHOW SLAVE STATUS;")

# Get the values of the relevant fields. More can be added as necessary.
IO_STATUS=$(echo "${SLAVE_STATUS}" | grep "Slave_IO_Running:" | cut -d: -f2 | sed -e 's/ //g')
SQL_STATUS=$(echo "${SLAVE_STATUS}" | grep "Slave_SQL_Running:" | cut -d: -f2 | sed -e 's/ //g')
SECONDS_BEHIND=$(echo "${SLAVE_STATUS}" | grep "Seconds_Behind_Master:" | cut -d: -f2 | sed -e 's/ //g')
LAST_ERRNO=$(echo "${SLAVE_STATUS}" | grep "Last_Errno:" | cut -d: -f2 | sed -e 's/ //g')

# Check each fields whether the value should trigger an alert.
ALERT=0
if [ "${IO_STATUS}" != "Yes" -o "${SQL_STATUS}" != "Yes" -o "${LAST_ERRNO}" != "0" ]; then
   ALERT=1
elif (( SECONDS_BEHIND > DELAY_THRESHOLD )); then
   ALERT=1
fi

# If there is something to alert about, output SLAVE_STATUS. This can optionally
# be done through an email service such as postfix.
if [ "${ALERT}" == "1" ]; then
   echo "Replication status is not as expected."
   echo
   echo "Output of SHOW SLAVE STATUS\G"
   echo "${SLAVE_STATUS}"

   exit 1
fi

exit 0

###############################################################################

# killing sleep connections

 for i in `mysqladmin -u root -pc17h35coona processlist | grep -i Sleep | awk '{print $2}'`;do mysql -u root -pc17h35coona -e "kill $i"; done 

###############################################################################

# dumping n number of tables parallely

for i in `cat test`; do "mysqldump reseller_db ${i} > /home/roopesh/${i}.sql"; sleep 2; done 

for i in `cat new`; do echo "processing $i" && mysqldump reseller_db $i > $i.sql ; done 
for i in `cat test`; do echo "processing $i" && mysql reseller_db < $i.sql ; done 
for i in `cat new` ; do echo "processing $i" && scp $i.sql roopesh@172.29.67.171: 
for i in `cat new` ; do echo "processing $i" && scp $i.sql roopesh@172.29.67.171:; done 
for i in *.sql; do echo "Processing $i" && gzip $i; done 
for i in tbl_clients_daily_categorywise_contribution_11062014 tbl_clients_daily_categorywise_contribution_11122013 tbl_clients_daily_categorywise_contribution_21052014 tbl_clients_daily_categorywise_contribution_21122013; do echo Count for $i && sudo mysql -Bse "select count(1) from db_finance.$i;" ; done 
for X in 26 32 40 50 56; do scp /tmp/tbl_sb_*.gz web_backup@172.29.$X.222:/tmp/; done 

###############################################################################

## renaming database more than 1 TB

mysql -u username -ppassword old_db -sNe 'show tables' | while read table; \ 
do mysql -u username -ppassword -sNe "rename table old_db.$table to new_db.$table"; done

###############################################################################



******** QUESTIONS &  ANSWERS *******

indexes
https://atech.blog/viaduct/mysql-indexes-primer
https://dev.mysql.com/doc/refman/8.0/en/mysql-indexes.html


mysql installation
upgradation
backup and types
replication
show slave status paramaeters
types of binlog
types of replication
mysqldump options
explain
deadlock -- how to avoid
datatypes additioon in 5.7

error log, general log , slow logs
How can you change the root password if the root password is lost?


Mysql
5.5 vrs 5.6 vrs 5.7


storage engines
myisam and innodb
memory and csv storage engines


master master replicatino
multi master replication
partitioning and how to make it automatically monthly
online alter

locks and its modes shared exclusive gap lock
innodb vairables  
transaction isolation level
if deleted data from innodb table still space is not free ?? why(reindexing)
if replication broken then how to reset 
if autoicrement is max then how to insert new value

online backup
performance tuning
glera cluster
PMM tool or nagios
scripting 

--1
Restrict access To specific table 
High availability
3 master and 1 slave
One user 2 queries for 1 hour 
Rest can be any
What all parameters you will check in monitoring script
Multimaster replication,locking in innodb, xtrabackup
Alter online

-- 2
which replication mode aurora have and rds have 
how point in time recovery can be done on rds
how to prevent data loss on aws rds and aurora
mysql 5.6 and 5.7 performance enhancements
sort buffer and other buffers
innodb buffer pool size
explain and its values
in 5.5 which replication synch asynch semi synch
Feature mysql 8
GTID replication
mongo db
advantage of physical server
advatange of rds and aurora

--3
Starting from installation they started
What type of installation
Replication topilogies
Types of indexes
Diff btwn 5.6 and 5.7
Types of backup
Innodb tables backup in command line
Storage engines
Parameters need to check when database is slow 
Replication issues
Name two error codes with description
How to check mysql uptime in command line
What changes to be done in my.cnf when replication
Explain plan using query


-- 4
isolation level
mysql installation types 
why rpm and why binary installation
mysql upgrade
LVM snapshot
mysql utilities
mysqldump mysql show mysqladmin 
performance optimization
mysql important variables 
mysql network related variables
master master and master slave
how will u design database what all you will keep in mind
heap and temp table difference 


pid not FOUND
resolve duplicate entry
installation in mysql

rpm yum apt installation mysql

Performance optimisation
Server level(innodb variables), Application level(explain, indexing,union, join  ), Storage level (RAID, Storage strategies, core of cpu)


utf8 and utf8mb4
int(20) and char(20)
int(20) and bigint(20)
load increased in peak hours
number of connections increased from 500 to 1500(writes expand)
unique number generation
combination of aplpha numeric




installation
replication
optimization

10 variables which we can set in installation
replication
mysqlslow and other tools for slow query log
master data 0 1 2
innodb flush log at trx commit
innodb redo log file size
how locking done in myisam and innodb internally

backup >> percona backup step by step
percona tool kit


*** DETERMINISTIC - non-deterministic ***
******************************************

I think that your routine is deterministic. The documentation is not very clear and this has led to many people being very confused about this issue,
 which is actually more about replication than anything else.

Consider a situation where you have replication set up between two databases. 
The master database keeps a log of all the stored routines that were executed including their input parameters and ships this log to the the slave. 
 The slave executes the same stored routines in the same order with the same input parameters.
  Will the slave database now contain identical data to the master database? If the stored routines create GUIDs 
  and store these in the database then no, the master and slave databases will be different and replication will be broken.

The main purpose of the DETERMINISTIC flag is to tell MySQL whether including calls to this stored routine in the replication log will
 result in differences between the master database and the replicated slaves, and is therefore unsafe.

When deciding if the DETERMINISTIC flag is appropriate for a stored routine think of it like this:
 If I start with two identical databases and I execute my routine on both databases with the same input parameters will my databases still be identical? If they are then my routine is deterministic.

If you declare your routine is deterministic when it is not, then replicas of your main database might not be identical to the original 
because MySQL will only add the procedure call to the replication log, and executing the procedure on the slave does not produce identical results.

If your routine is non-deterministic then MySQL must include the affected rows in the replication log instead. If you declare your routine as non-deterministic 
when it is not this will not break anything, but the replication log will contain all of the affected rows 
when just the procedure call would have been enough 
and this could impact performance.


-- calendar

SET @date=0;
SELECT DATE_ADD(NOW() , INTERVAL @date:=@date+1 DAY)AS calendar,
DAYNAME(DATE_ADD(NOW() , INTERVAL @date DAY)) AS day_name,
DATE(DATE_ADD(NOW() , INTERVAL @date DAY)) AS `date`,
YEAR(DATE_ADD(NOW() , INTERVAL @date DAY)) AS `year` FROM abc LIMIT 365;


-- sample type : plasma
-- tube color  : sodium citrate




-- data not in 5 - 5 mins interval
-- 12:00:00
-- 12:05:00
-- 12:10:00

asm_pk  updated_Date         
------  ---------------------
     1  2018-11-17 12:05:18  
     2  2018-11-17 12:07:08  
     3  2018-11-17 12:12:16  
     4  2018-11-17 12:13:14  
     5  2018-11-17 12:24:11  
     6  2018-11-17 12:06:19  
     7  2018-11-17 12:08:12  
     8  2018-11-17 12:25:13  
     9  2018-11-17 12:29:15  
    10  2018-11-17 12:19:20  
	
-- 5 - 5 minutes difference data	

SELECT * FROM temp_date
WHERE MINUTE(updated_date)%5!=0;


-- importing huge files

mysql> use db_name;
mysql> SET autocommit=0 ; source the_sql_file.sql ; COMMIT ;

